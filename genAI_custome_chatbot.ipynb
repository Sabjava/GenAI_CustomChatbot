{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "124e5672",
      "metadata": {
        "id": "124e5672"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "# Custom Chatbot Project"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a4a94b3",
      "metadata": {
        "id": "2a4a94b3"
      },
      "source": [
        "The chosen dataset consists of concise news articles focusing on advancements in generative AI, including breakthroughs in technologies like GPT models, their applications in education and business communication, and industry trends such as competition among AI companies. Each record is a self-contained text field, formatted with the year, a brief description of the news, and the source, ensuring clarity and relevance. This dataset is particularly appropriate for the task as it directly aligns with the focus on generative AI, covers diverse and credible topics, and provides well-structured information that facilitates efficient processing using text embedding models like `text-embedding-ada-002`. Its real-world context and factual nature make it ideal for both retrieving contextually relevant answers and comparing results from embedding-based custom queries with general knowledge-based completion models."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a63d4c5f",
      "metadata": {
        "id": "a63d4c5f"
      },
      "source": [
        "## Data Wrangling\n",
        "\n",
        "TODO: In the cells below, load your chosen dataset into a `pandas` dataframe with a column named `\"text\"`. This column should contain all of your text data, separated into at least 20 rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c69b83a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "c69b83a1",
        "outputId": "a418ecbe-b25f-4198-ec58-df8210b6c588"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text\n",
              "count                                                  54\n",
              "unique                                                 54\n",
              "top     2023 - Generative Pre-trained Transformers (GP...\n",
              "freq                                                    1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a9df436-ae05-45e8-980c-e305f69a1f97\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>2023 - Generative Pre-trained Transformers (GP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a9df436-ae05-45e8-980c-e305f69a1f97')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7a9df436-ae05-45e8-980c-e305f69a1f97 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7a9df436-ae05-45e8-980c-e305f69a1f97');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-69befc51-ca68-4004-938f-7c8107611758\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-69befc51-ca68-4004-938f-7c8107611758')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-69befc51-ca68-4004-938f-7c8107611758 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"54\",\n          \"2023 - Generative Pre-trained Transformers (GPT) continue to set benchmarks in natural language processing, enabling more human-like interactions, accurate translations, and complex text generation. These advancements make AI more accessible and useful in areas like education and business communication OpenAI, https://openai.com/research\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/genAI_advances.csv')\n",
        "df['text'] = df['year'].astype(str) + ' - ' + df['content'] + ' ' + df['source']\n",
        "df = df[['text']]\n",
        "\n",
        "# Display the DataFrame\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "id": "5vX1KVczP11J",
        "outputId": "27f7a1aa-f3f3-4abd-fd42-db56a908c367"
      },
      "id": "5vX1KVczP11J",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2024.12.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.59.9\n",
            "    Uninstalling openai-1.59.9:\n",
            "      Successfully uninstalled openai-1.59.9\n",
            "Successfully installed openai-0.28.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "openai"
                ]
              },
              "id": "a76898d05efe4e33a0acf26768067f01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2024.12.14)\n",
            "Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.2 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0a595980",
      "metadata": {
        "id": "0a595980"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import openai\n",
        "import os\n",
        "from openai.embeddings_utils import distances_from_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "acb3a9fd",
      "metadata": {
        "id": "acb3a9fd"
      },
      "outputs": [],
      "source": [
        "openai.api_key = 'voc-.xxx'\n",
        "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
        "MAX_TOKENS = 1000\n",
        "openai.api_base = \"https://openai.vocareum.com/v1\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae769871",
      "metadata": {
        "id": "ae769871"
      },
      "source": [
        "## Custom Query Completion\n",
        "\n",
        "TODO: In the cells below, compose a custom query using your chosen dataset and retrieve results from an OpenAI `Completion` model. You may copy and paste any useful code from the course materials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5ce6c139",
      "metadata": {
        "id": "5ce6c139"
      },
      "outputs": [],
      "source": [
        "def query_openai(query):\n",
        "    # Select a relevant piece of text from the DataFrame based on the query\n",
        "    context = df['text'].sample(1).iloc[0]  # This selects one random row for context\n",
        "\n",
        "    # Format the query with context\n",
        "    prompt = f\"Context:\\n{context}\\n\\nQuery:\\n{query}\\n\\nAnswer:\"\n",
        "\n",
        "    # Call the OpenAI Completion API\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"gpt-3.5-turbo-instruct\",\n",
        "        prompt=prompt,\n",
        "        max_tokens=50,  # Adjust as needed\n",
        "        n=1,\n",
        "        stop=None,\n",
        "        temperature=0.7,  # Adjust as needed\n",
        "    )\n",
        "\n",
        "    # Extract and return the answer\n",
        "    answer = response.choices[0].text.strip()\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4bea1fce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bea1fce",
        "outputId": "c8cf26ce-6b4a-4a9b-815b-25c7673e8e0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLaMA (Language Learning with Machine Assistance) is a research project by OpenAI that aims to improve language learning by combining the power of generative pre-trained transformers (GPT) with human teaching. It uses AI to generate personalized practice exercises\n"
          ]
        }
      ],
      "source": [
        "query = \"What is LLaMA?\"\n",
        "answer = query_openai(query)\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "13f2dcd7",
      "metadata": {
        "id": "13f2dcd7"
      },
      "outputs": [],
      "source": [
        "embeddings = []\n",
        "for index, row in df.iterrows():\n",
        "  response = openai.Embedding.create(\n",
        "      input=row[\"text\"],\n",
        "      engine=EMBEDDING_MODEL_NAME\n",
        "  )\n",
        "  embeddings.extend([data[\"embedding\"] for data in response[\"data\"]])\n",
        "df[\"embeddings\"] = embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c403f543",
      "metadata": {
        "id": "c403f543"
      },
      "outputs": [],
      "source": [
        "df[[\"text\", \"embeddings\"]].to_csv(\"genAI_news_embeddings.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "74280b92",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "74280b92",
        "outputId": "419a71d0-0c25-4997-9589-1edea0284ec3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  2023 - Generative Pre-trained Transformers (GP...   \n",
              "1  2023 - Diffusion models emerge as a transforma...   \n",
              "2  2024 - OpenAI's DALL·E 3 brings unprecedented ...   \n",
              "3  2023 - Meta introduces LLaMA, a large language...   \n",
              "4  2024 - Google DeepMind unveils Gemini, a langu...   \n",
              "\n",
              "                                          embeddings  \n",
              "0  [-0.015429225750267506, -0.030154043808579445,...  \n",
              "1  [-0.015209694392979145, -0.003470304422080517,...  \n",
              "2  [-0.019175244495272636, -0.020816493779420853,...  \n",
              "3  [-0.014117571525275707, 0.01502192486077547, 0...  \n",
              "4  [-0.014261371456086636, 0.005189887247979641, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1305e924-1971-4d82-8777-c1aaa2c51e39\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>embeddings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023 - Generative Pre-trained Transformers (GP...</td>\n",
              "      <td>[-0.015429225750267506, -0.030154043808579445,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023 - Diffusion models emerge as a transforma...</td>\n",
              "      <td>[-0.015209694392979145, -0.003470304422080517,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2024 - OpenAI's DALL·E 3 brings unprecedented ...</td>\n",
              "      <td>[-0.019175244495272636, -0.020816493779420853,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2023 - Meta introduces LLaMA, a large language...</td>\n",
              "      <td>[-0.014117571525275707, 0.01502192486077547, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2024 - Google DeepMind unveils Gemini, a langu...</td>\n",
              "      <td>[-0.014261371456086636, 0.005189887247979641, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1305e924-1971-4d82-8777-c1aaa2c51e39')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1305e924-1971-4d82-8777-c1aaa2c51e39 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1305e924-1971-4d82-8777-c1aaa2c51e39');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ea5aff8f-ce46-4d81-aba8-85b342911cae\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ea5aff8f-ce46-4d81-aba8-85b342911cae')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ea5aff8f-ce46-4d81-aba8-85b342911cae button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 54,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 54,\n        \"samples\": [\n          \"2023 - AI content moderation tools leverage generative models to identify and mitigate harmful material, promoting safer online environments OpenAI, https://openai.com/research/content-moderation\",\n          \"2025 - The global market for generative AI is projected to reach $200 billion, driven by innovations in content creation and personalized marketing. http://markettrendsreport.com\",\n          \"2025 - Generative AI models are now widely used in gaming to create immersive environments and unique storylines tailored to each player. http://gamingtoday.com\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embeddings\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df = pd.read_csv('genAI_news_embeddings.csv', index_col=0)\n",
        "df[\"embeddings\"] = df[\"embeddings\"].apply(eval).apply(np.array)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1783f146",
      "metadata": {
        "id": "1783f146"
      },
      "source": [
        "## Custom Performance Demonstration\n",
        "\n",
        "TODO: In the cells below, demonstrate the performance of your custom query using at least 2 questions. For each question, show the answer from a basic `Completion` model query as well as the answer from your custom query."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f11fdc0",
      "metadata": {
        "id": "4f11fdc0"
      },
      "source": [
        "### Question 1,2,3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "4901c850",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4901c850",
        "outputId": "2b09f6e1-f23b-4794-e6ae-0ff13c9c2068"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"cmpl-AuqiItkJ0ofgm6JbZRH4ghsUrnjWD\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"created\": 1738112362,\n",
            "  \"model\": \"gpt-3.5-turbo-instruct\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"text\": \"\\n\\nGPT (Generative Pre-trained Transformer) models have made significant advancements in natural language processing (NLP) by improving language understanding and generation tasks. These models use deep learning algorithms and large training datasets to achieve state-of-the-art performance in various NLP tasks. Some of the advancements made by GPT models in NLP include:\\n\\n1. Improving language generation: GPT models can generate human-like text by predicting the next word or sentence based on the context. This has been applied in\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"length\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 21,\n",
            "    \"completion_tokens\": 100,\n",
            "    \"total_tokens\": 121\n",
            "  }\n",
            "}\n",
            "Question 1: What advancements have GPT models made in natural language processing?\n",
            "Custom Query Answer: 2023 - Generative Pre-trained Transformers (GPT) continue to set benchmarks in natural language processing, enabling more human-like interactions, accurate translations, and complex text generation. These advancements make AI more accessible and useful in areas like education and business communication OpenAI, https://openai.com/research\n",
            "Completion Model Answer: GPT (Generative Pre-trained Transformer) models have made significant advancements in natural language processing (NLP) by improving language understanding and generation tasks. These models use deep learning algorithms and large training datasets to achieve state-of-the-art performance in various NLP tasks. Some of the advancements made by GPT models in NLP include:\n",
            "\n",
            "1. Improving language generation: GPT models can generate human-like text by predicting the next word or sentence based on the context. This has been applied in\n",
            "\n",
            "{\n",
            "  \"id\": \"cmpl-AuqiJsTkplk2CUyCWSCmR3cUu3pDL\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"created\": 1738112363,\n",
            "  \"model\": \"gpt-3.5-turbo-instruct\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"text\": \"\\n\\nDeepSeek was a web search engine based on the concept of \\\"deep web\\\" searching. It specialized in searching for hard-to-find information such as scientific research papers, government records, and other databases not easily indexed by traditional search engines. It was created in 1997 by Dr. Mark Bergman and was acquired by AOL in 1999 before ultimately being shut down in 2001. \",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 14,\n",
            "    \"completion_tokens\": 81,\n",
            "    \"total_tokens\": 95\n",
            "  }\n",
            "}\n",
            "Question 2: What DeepSeek did?\n",
            "Custom Query Answer: 2025 - Chinese startup DeepSeek has debuted an AI app that challenges OpenAI's ChatGPT and other U.S. rivals, sending a shock through Wall Street. http://cnn.com\n",
            "Completion Model Answer: DeepSeek was a web search engine based on the concept of \"deep web\" searching. It specialized in searching for hard-to-find information such as scientific research papers, government records, and other databases not easily indexed by traditional search engines. It was created in 1997 by Dr. Mark Bergman and was acquired by AOL in 1999 before ultimately being shut down in 2001.\n",
            "\n",
            "{\n",
            "  \"id\": \"cmpl-AuqiLCbrtAYN7ddnMEY1DGyEO5NwL\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"created\": 1738112365,\n",
            "  \"model\": \"gpt-3.5-turbo-instruct\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"text\": \"\\n\\nLLaMA stands for \\\"Learning and Living with Multiple Allergies,\\\" and is a non-profit organization that aims to support individuals and families living with multiple food allergies.\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 15,\n",
            "    \"completion_tokens\": 35,\n",
            "    \"total_tokens\": 50\n",
            "  }\n",
            "}\n",
            "Question 3: What is LLaMA?\n",
            "Custom Query Answer: 2023 - Meta introduces LLaMA, a large language model optimized for efficiency and scalability. LLaMA focuses on democratizing AI access while reducing computational costs for small-scale deployments Meta, https://ai.facebook.com/research\n",
            "Completion Model Answer: LLaMA stands for \"Learning and Living with Multiple Allergies,\" and is a non-profit organization that aims to support individuals and families living with multiple food allergies.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "questions = [\n",
        "    \"What advancements have GPT models made in natural language processing?\",\n",
        "    \"What DeepSeek did?\",\n",
        "    \"What is LLaMA?\"\n",
        "]\n",
        "\n",
        "# Generate embeddings for questions\n",
        "question_embeddings = []\n",
        "for question in questions:\n",
        "    response = openai.Embedding.create(\n",
        "        input=question,\n",
        "        engine=EMBEDDING_MODEL_NAME\n",
        "    )\n",
        "    question_embeddings.append(response[\"data\"][0][\"embedding\"])\n",
        "\n",
        "# Custom query: Find the closest match using cosine similarity\n",
        "for i, question_embedding in enumerate(question_embeddings):\n",
        "    similarities = cosine_similarity(\n",
        "        [question_embedding], df[\"embeddings\"].tolist()\n",
        "    )[0]\n",
        "    closest_index = np.argmax(similarities)\n",
        "    custom_answer = df.iloc[closest_index][\"text\"]\n",
        "\n",
        "    # Completion model query\n",
        "    completion_response = openai.Completion.create(\n",
        "        model=\"gpt-3.5-turbo-instruct\",\n",
        "        prompt=f\"Answer the following question based on general knowledge: {questions[i]}\",\n",
        "        max_tokens=100\n",
        "    )\n",
        "    print(completion_response)\n",
        "\n",
        "    completion_answer = completion_response[\"choices\"][0][\"text\"].strip()\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Question {i + 1}: {questions[i]}\")\n",
        "    print(f\"Custom Query Answer: {custom_answer}\")\n",
        "    print(f\"Completion Model Answer: {completion_answer}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h-x0-JBebp0k"
      },
      "id": "h-x0-JBebp0k"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
